{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### Import libraries and create data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.39'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fastai\n",
    "fastai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.vision.image import *\n",
    "from fastai.callbacks import *\n",
    "import torchvision\n",
    "from fastai import basic_train\n",
    "from torchvision.models.inception import BasicConv2d, InceptionA, InceptionB, InceptionC, InceptionD, InceptionE, InceptionAux\n",
    "\n",
    "import cv2\n",
    "\n",
    "from torchvision import models\n",
    "from pretrainedmodels.models import bninception\n",
    "from torch import nn\n",
    "from collections import OrderedDict\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class DefaultConfigs(object):\n",
    "    train_data = \"data/train/\" # where is your train data\n",
    "    test_data = \"data/test/\"   # your test data\n",
    "    weights = \"data/checkpoints/\"\n",
    "    best_models = \"data/checkpoints/best_models/\"\n",
    "    submit = \"data/submit/\"\n",
    "    model_name = \"data/bninception_bcelog_grad_accu\"\n",
    "    num_classes = 28\n",
    "    img_weight = 512\n",
    "    img_height = 512\n",
    "    channels = 4\n",
    "    lr = 0.03\n",
    "    batch_size = 32\n",
    "    epochs = 50\n",
    "\n",
    "config = DefaultConfigs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_net():\n",
    "    model = bninception(pretrained=\"imagenet\")\n",
    "    model.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "    model.conv1_7x7_s2 = nn.Conv2d(config.channels, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
    "    model.last_linear = nn.Sequential(\n",
    "                nn.BatchNorm1d(1024),\n",
    "                nn.Dropout(0.5),\n",
    "                nn.Linear(1024, config.num_classes),\n",
    "            )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def open_4_channel(fname):\n",
    "    fname = str(fname)\n",
    "    suffix = '.png'\n",
    "    # strip extension before adding color\n",
    "    if fname.endswith('.png') or fname.endswith('.tif'):\n",
    "        suffix = fname[-4:]\n",
    "        fname = fname[:-4]\n",
    "\n",
    "    colors = ['red','green','blue','yellow']\n",
    "    flags = cv2.IMREAD_GRAYSCALE\n",
    "    img = [cv2.imread(fname+'_'+color+suffix, flags).astype(np.float32)/255\n",
    "           for color in colors]\n",
    "    \n",
    "    x = np.stack(img, axis=-1)\n",
    "    return Image(pil2tensor(x, np.float32).float())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bs = 8\n",
    "\n",
    "path = Path('data')\n",
    "df = pd.read_csv(path/'train.csv')\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "src = (ImageItemList.from_csv(path, 'train.csv', folder='train', suffix='.png')\n",
    "       .random_split_by_pct(0.2)\n",
    "       .label_from_df(sep=' ',  classes=[str(i) for i in range(28)]))\n",
    "\n",
    "src.train.x.create_func = open_4_channel\n",
    "src.train.x.open = open_4_channel\n",
    "\n",
    "\n",
    "src.valid.x.create_func = open_4_channel\n",
    "src.valid.x.open = open_4_channel\n",
    "\n",
    "test_ids = list(sorted({fname.split('_')[0] for fname in os.listdir(path/'test')}))\n",
    "\n",
    "test_fnames = [path/'test'/test_id for test_id in test_ids]\n",
    "\n",
    "src.add_test(test_fnames, label='0');\n",
    "src.test.x.create_func = open_4_channel\n",
    "src.test.x.open = open_4_channel\n",
    "\n",
    "protein_stats = ([0.08069, 0.05258, 0.05487, 0.08282], [0.13704, 0.10145, 0.15313, 0.13814])\n",
    "trn_tfms,_ = get_transforms(do_flip=True, flip_vert=True, max_rotate=30., max_zoom=1,\n",
    "                      max_lighting=0.05, max_warp=0.)\n",
    "\n",
    "data = (src.transform((trn_tfms, _), size=512).databunch(num_workers=0).normalize(protein_stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def _resnet_split(m): return (m[0][6],m[1])\n",
    "def _default_split(m:nn.Module): return (m[1],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f1_score = partial(fbeta, thresh=0.2, beta=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### Try 1 with Adam\n",
    "best score 0.457"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loss_fn = F.binary_cross_entropy_with_logits\n",
    "model = get_net()\n",
    "model = model.cuda()\n",
    "optim = torch.optim.Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def custom_loss_func(model:nn.Module, xb:Tensor, yb:Tensor, loss_func:OptLossFunc=None, opt:OptOptimizer=None,\n",
    "               cb_handler:Optional[CallbackHandler]=None)->Tuple[Union[Tensor,int,float,str]]:\n",
    "    if not is_listy(xb): xb = [xb]\n",
    "    if not is_listy(yb): yb = [yb]\n",
    "    out = model(*xb)\n",
    "    out = cb_handler.on_loss_begin(out)\n",
    "\n",
    "    if not loss_func: return to_detach(out), yb[0].detach()\n",
    "    loss = loss_func(out, *yb)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def custom_fit(epochs:int, model:nn.Module, loss_func:LossFunction, opt:torch.optim.Optimizer,\n",
    "        data:DataBunch, callbacks:Optional[CallbackList]=None, metrics:OptMetrics=None,\n",
    "        gradient_accumulation_steps:int=16)->None:\n",
    "    \"Fit the `model` on `data` and learn using `loss_func` and `opt`.\"\n",
    "    cb_handler = CallbackHandler(callbacks, metrics)\n",
    "    pbar = master_bar(range(epochs))\n",
    "    cb_handler.on_train_begin(epochs, pbar=pbar, metrics=metrics)\n",
    "\n",
    "    exception=False\n",
    "    try:\n",
    "        for epoch in pbar:\n",
    "            step = 0\n",
    "            model.train()\n",
    "            cb_handler.on_epoch_begin()\n",
    "\n",
    "            for xb,yb in progress_bar(data.train_dl, parent=pbar):\n",
    "                xb, yb = cb_handler.on_batch_begin(xb, yb)\n",
    "                \n",
    "                loss = custom_loss_func(model, xb, yb, loss_func, cb_handler=cb_handler)\n",
    "                \n",
    "#                 if gradient_accumulation_steps > 1:\n",
    "#                     loss = loss / gradient_accumulation_steps\n",
    "                \n",
    "                loss = cb_handler.on_backward_begin(loss)\n",
    "                loss.backward()\n",
    "                cb_handler.on_backward_end()\n",
    "\n",
    "                if (step + 1) % gradient_accumulation_steps == 0:\n",
    "#                     print(\"Step:\", step, flush=True)\n",
    "                    opt.step()\n",
    "                    cb_handler.on_step_end()\n",
    "                    opt.zero_grad()\n",
    "                step += 1\n",
    "                \n",
    "                loss = loss.detach().cpu()  \n",
    "                if cb_handler.on_batch_end(loss): break\n",
    "\n",
    "            if not data.empty_val:\n",
    "                val_loss = validate(model, data.valid_dl, loss_func=loss_func, cb_handler=cb_handler, \n",
    "                                    pbar=pbar)\n",
    "            else: val_loss=None\n",
    "            if cb_handler.on_epoch_end(val_loss): break\n",
    "    except Exception as e:\n",
    "        exception = e\n",
    "        raise e\n",
    "    finally: cb_handler.on_train_end(exception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "defaults.lr = slice(3e-3)\n",
    "defaults.wd = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class custom_learner(basic_train.Learner):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "    def fit(self, epochs:int, lr:Union[Floats,slice]=defaults.lr, wd:Floats=None, \n",
    "            callbacks:Collection[Callback]=None) -> None:\n",
    "        lr = self.lr_range(lr)\n",
    "        if wd is None: wd = self.wd\n",
    "        if not getattr(self, 'opt', False): self.create_opt(lr, wd)\n",
    "        else: self.opt.lr,self.opt.wd = lr,wd\n",
    "        callbacks = [cb(self) for cb in self.callback_fns] + listify(callbacks)\n",
    "        custom_fit(epochs, self.model, self.loss_func, opt=self.opt, data=self.data, metrics=self.metrics,\n",
    "            callbacks=self.callbacks+callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn = custom_learner(data, model, opt_func=optim, loss_func=loss_fn, metrics=[f1_score], \n",
    "                           callback_fns=[partial(ReduceLROnPlateauCallback, monitor='val_loss', \n",
    "                                                 patience=3),\n",
    "                                         partial(EarlyStoppingCallback, monitor='val_loss', \n",
    "                                                 min_delta=0.001, patience=6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "custom_learner(data=ImageDataBunch;\n",
       "\n",
       "Train: LabelList\n",
       "y: MultiCategoryList (24858 items)\n",
       "[MultiCategory 16;0, MultiCategory 7;1;2;0, MultiCategory 5, MultiCategory 1, MultiCategory 18]...\n",
       "Path: data\n",
       "x: ImageItemList (24858 items)\n",
       "[Image (4, 512, 512), Image (4, 512, 512), Image (4, 512, 512), Image (4, 512, 512), Image (4, 512, 512)]...\n",
       "Path: data;\n",
       "\n",
       "Valid: LabelList\n",
       "y: MultiCategoryList (6214 items)\n",
       "[MultiCategory 12;23;0, MultiCategory 0, MultiCategory 1;0, MultiCategory 25;5, MultiCategory 23]...\n",
       "Path: data\n",
       "x: ImageItemList (6214 items)\n",
       "[Image (4, 512, 512), Image (4, 512, 512), Image (4, 512, 512), Image (4, 512, 512), Image (4, 512, 512)]...\n",
       "Path: data;\n",
       "\n",
       "Test: LabelList\n",
       "y: MultiCategoryList (11702 items)\n",
       "[MultiCategory 0, MultiCategory 0, MultiCategory 0, MultiCategory 0, MultiCategory 0]...\n",
       "Path: data\n",
       "x: ImageItemList (11702 items)\n",
       "[Image (4, 512, 512), Image (4, 512, 512), Image (4, 512, 512), Image (4, 512, 512), Image (4, 512, 512)]...\n",
       "Path: data, model=BNInception(\n",
       "  (conv1_7x7_s2): Conv2d(4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "  (conv1_7x7_s2_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv1_relu_7x7): ReLU(inplace)\n",
       "  (pool1_3x3_s2): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=0, dilation=(1, 1), ceil_mode=True)\n",
       "  (conv2_3x3_reduce): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (conv2_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2_relu_3x3_reduce): ReLU(inplace)\n",
       "  (conv2_3x3): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2_3x3_bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2_relu_3x3): ReLU(inplace)\n",
       "  (pool2_3x3_s2): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=0, dilation=(1, 1), ceil_mode=True)\n",
       "  (inception_3a_1x1): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_3a_1x1_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_3a_relu_1x1): ReLU(inplace)\n",
       "  (inception_3a_3x3_reduce): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_3a_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_3a_relu_3x3_reduce): ReLU(inplace)\n",
       "  (inception_3a_3x3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_3a_3x3_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_3a_relu_3x3): ReLU(inplace)\n",
       "  (inception_3a_double_3x3_reduce): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_3a_double_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_3a_relu_double_3x3_reduce): ReLU(inplace)\n",
       "  (inception_3a_double_3x3_1): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_3a_double_3x3_1_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_3a_relu_double_3x3_1): ReLU(inplace)\n",
       "  (inception_3a_double_3x3_2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_3a_double_3x3_2_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_3a_relu_double_3x3_2): ReLU(inplace)\n",
       "  (inception_3a_pool): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "  (inception_3a_pool_proj): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_3a_pool_proj_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_3a_relu_pool_proj): ReLU(inplace)\n",
       "  (inception_3b_1x1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_3b_1x1_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_3b_relu_1x1): ReLU(inplace)\n",
       "  (inception_3b_3x3_reduce): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_3b_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_3b_relu_3x3_reduce): ReLU(inplace)\n",
       "  (inception_3b_3x3): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_3b_3x3_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_3b_relu_3x3): ReLU(inplace)\n",
       "  (inception_3b_double_3x3_reduce): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_3b_double_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_3b_relu_double_3x3_reduce): ReLU(inplace)\n",
       "  (inception_3b_double_3x3_1): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_3b_double_3x3_1_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_3b_relu_double_3x3_1): ReLU(inplace)\n",
       "  (inception_3b_double_3x3_2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_3b_double_3x3_2_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_3b_relu_double_3x3_2): ReLU(inplace)\n",
       "  (inception_3b_pool): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "  (inception_3b_pool_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_3b_pool_proj_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_3b_relu_pool_proj): ReLU(inplace)\n",
       "  (inception_3c_3x3_reduce): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_3c_3x3_reduce_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_3c_relu_3x3_reduce): ReLU(inplace)\n",
       "  (inception_3c_3x3): Conv2d(128, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (inception_3c_3x3_bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_3c_relu_3x3): ReLU(inplace)\n",
       "  (inception_3c_double_3x3_reduce): Conv2d(320, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_3c_double_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_3c_relu_double_3x3_reduce): ReLU(inplace)\n",
       "  (inception_3c_double_3x3_1): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_3c_double_3x3_1_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_3c_relu_double_3x3_1): ReLU(inplace)\n",
       "  (inception_3c_double_3x3_2): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (inception_3c_double_3x3_2_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_3c_relu_double_3x3_2): ReLU(inplace)\n",
       "  (inception_3c_pool): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=0, dilation=(1, 1), ceil_mode=True)\n",
       "  (inception_4a_1x1): Conv2d(576, 224, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_4a_1x1_bn): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4a_relu_1x1): ReLU(inplace)\n",
       "  (inception_4a_3x3_reduce): Conv2d(576, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_4a_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4a_relu_3x3_reduce): ReLU(inplace)\n",
       "  (inception_4a_3x3): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_4a_3x3_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4a_relu_3x3): ReLU(inplace)\n",
       "  (inception_4a_double_3x3_reduce): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_4a_double_3x3_reduce_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4a_relu_double_3x3_reduce): ReLU(inplace)\n",
       "  (inception_4a_double_3x3_1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_4a_double_3x3_1_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4a_relu_double_3x3_1): ReLU(inplace)\n",
       "  (inception_4a_double_3x3_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_4a_double_3x3_2_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4a_relu_double_3x3_2): ReLU(inplace)\n",
       "  (inception_4a_pool): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "  (inception_4a_pool_proj): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_4a_pool_proj_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4a_relu_pool_proj): ReLU(inplace)\n",
       "  (inception_4b_1x1): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_4b_1x1_bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4b_relu_1x1): ReLU(inplace)\n",
       "  (inception_4b_3x3_reduce): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_4b_3x3_reduce_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4b_relu_3x3_reduce): ReLU(inplace)\n",
       "  (inception_4b_3x3): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_4b_3x3_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4b_relu_3x3): ReLU(inplace)\n",
       "  (inception_4b_double_3x3_reduce): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_4b_double_3x3_reduce_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4b_relu_double_3x3_reduce): ReLU(inplace)\n",
       "  (inception_4b_double_3x3_1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_4b_double_3x3_1_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4b_relu_double_3x3_1): ReLU(inplace)\n",
       "  (inception_4b_double_3x3_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_4b_double_3x3_2_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4b_relu_double_3x3_2): ReLU(inplace)\n",
       "  (inception_4b_pool): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "  (inception_4b_pool_proj): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_4b_pool_proj_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4b_relu_pool_proj): ReLU(inplace)\n",
       "  (inception_4c_1x1): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_4c_1x1_bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4c_relu_1x1): ReLU(inplace)\n",
       "  (inception_4c_3x3_reduce): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_4c_3x3_reduce_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4c_relu_3x3_reduce): ReLU(inplace)\n",
       "  (inception_4c_3x3): Conv2d(128, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_4c_3x3_bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4c_relu_3x3): ReLU(inplace)\n",
       "  (inception_4c_double_3x3_reduce): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_4c_double_3x3_reduce_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4c_relu_double_3x3_reduce): ReLU(inplace)\n",
       "  (inception_4c_double_3x3_1): Conv2d(128, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_4c_double_3x3_1_bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4c_relu_double_3x3_1): ReLU(inplace)\n",
       "  (inception_4c_double_3x3_2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_4c_double_3x3_2_bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4c_relu_double_3x3_2): ReLU(inplace)\n",
       "  (inception_4c_pool): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "  (inception_4c_pool_proj): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_4c_pool_proj_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4c_relu_pool_proj): ReLU(inplace)\n",
       "  (inception_4d_1x1): Conv2d(608, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_4d_1x1_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4d_relu_1x1): ReLU(inplace)\n",
       "  (inception_4d_3x3_reduce): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_4d_3x3_reduce_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4d_relu_3x3_reduce): ReLU(inplace)\n",
       "  (inception_4d_3x3): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_4d_3x3_bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4d_relu_3x3): ReLU(inplace)\n",
       "  (inception_4d_double_3x3_reduce): Conv2d(608, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_4d_double_3x3_reduce_bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4d_relu_double_3x3_reduce): ReLU(inplace)\n",
       "  (inception_4d_double_3x3_1): Conv2d(160, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_4d_double_3x3_1_bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4d_relu_double_3x3_1): ReLU(inplace)\n",
       "  (inception_4d_double_3x3_2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_4d_double_3x3_2_bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4d_relu_double_3x3_2): ReLU(inplace)\n",
       "  (inception_4d_pool): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "  (inception_4d_pool_proj): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_4d_pool_proj_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4d_relu_pool_proj): ReLU(inplace)\n",
       "  (inception_4e_3x3_reduce): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_4e_3x3_reduce_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4e_relu_3x3_reduce): ReLU(inplace)\n",
       "  (inception_4e_3x3): Conv2d(128, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (inception_4e_3x3_bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4e_relu_3x3): ReLU(inplace)\n",
       "  (inception_4e_double_3x3_reduce): Conv2d(608, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_4e_double_3x3_reduce_bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4e_relu_double_3x3_reduce): ReLU(inplace)\n",
       "  (inception_4e_double_3x3_1): Conv2d(192, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_4e_double_3x3_1_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4e_relu_double_3x3_1): ReLU(inplace)\n",
       "  (inception_4e_double_3x3_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (inception_4e_double_3x3_2_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_4e_relu_double_3x3_2): ReLU(inplace)\n",
       "  (inception_4e_pool): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=0, dilation=(1, 1), ceil_mode=True)\n",
       "  (inception_5a_1x1): Conv2d(1056, 352, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_5a_1x1_bn): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_5a_relu_1x1): ReLU(inplace)\n",
       "  (inception_5a_3x3_reduce): Conv2d(1056, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_5a_3x3_reduce_bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_5a_relu_3x3_reduce): ReLU(inplace)\n",
       "  (inception_5a_3x3): Conv2d(192, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_5a_3x3_bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_5a_relu_3x3): ReLU(inplace)\n",
       "  (inception_5a_double_3x3_reduce): Conv2d(1056, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_5a_double_3x3_reduce_bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_5a_relu_double_3x3_reduce): ReLU(inplace)\n",
       "  (inception_5a_double_3x3_1): Conv2d(160, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_5a_double_3x3_1_bn): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_5a_relu_double_3x3_1): ReLU(inplace)\n",
       "  (inception_5a_double_3x3_2): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_5a_double_3x3_2_bn): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_5a_relu_double_3x3_2): ReLU(inplace)\n",
       "  (inception_5a_pool): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "  (inception_5a_pool_proj): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_5a_pool_proj_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_5a_relu_pool_proj): ReLU(inplace)\n",
       "  (inception_5b_1x1): Conv2d(1024, 352, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_5b_1x1_bn): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_5b_relu_1x1): ReLU(inplace)\n",
       "  (inception_5b_3x3_reduce): Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_5b_3x3_reduce_bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_5b_relu_3x3_reduce): ReLU(inplace)\n",
       "  (inception_5b_3x3): Conv2d(192, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_5b_3x3_bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_5b_relu_3x3): ReLU(inplace)\n",
       "  (inception_5b_double_3x3_reduce): Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_5b_double_3x3_reduce_bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_5b_relu_double_3x3_reduce): ReLU(inplace)\n",
       "  (inception_5b_double_3x3_1): Conv2d(192, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_5b_double_3x3_1_bn): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_5b_relu_double_3x3_1): ReLU(inplace)\n",
       "  (inception_5b_double_3x3_2): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (inception_5b_double_3x3_2_bn): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_5b_relu_double_3x3_2): ReLU(inplace)\n",
       "  (inception_5b_pool): MaxPool2d(kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), ceil_mode=True)\n",
       "  (inception_5b_pool_proj): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (inception_5b_pool_proj_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (inception_5b_relu_pool_proj): ReLU(inplace)\n",
       "  (global_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (last_linear): Sequential(\n",
       "    (0): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Dropout(p=0.5)\n",
       "    (2): Linear(in_features=1024, out_features=28, bias=True)\n",
       "  )\n",
       "), opt_func=<class 'torch.optim.adam.Adam'>, loss_func=<function binary_cross_entropy_with_logits at 0x7f26293ee7b8>, metrics=[functools.partial(<function fbeta at 0x7f2612be52f0>, thresh=0.2, beta=1)], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('data'), model_dir='models', callback_fns=[<class 'fastai.basic_train.Recorder'>, functools.partial(<class 'fastai.callbacks.tracker.ReduceLROnPlateauCallback'>, monitor='val_loss', patience=3), functools.partial(<class 'fastai.callbacks.tracker.EarlyStoppingCallback'>, monitor='val_loss', min_delta=0.001, patience=6)], callbacks=[], layer_groups=[Sequential(\n",
       "  (0): Conv2d(4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace)\n",
       "  (3): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=0, dilation=(1, 1), ceil_mode=True)\n",
       "  (4): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (6): ReLU(inplace)\n",
       "  (7): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (8): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (9): ReLU(inplace)\n",
       "  (10): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=0, dilation=(1, 1), ceil_mode=True)\n",
       "  (11): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (13): ReLU(inplace)\n",
       "  (14): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (15): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (16): ReLU(inplace)\n",
       "  (17): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (18): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (19): ReLU(inplace)\n",
       "  (20): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (21): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (22): ReLU(inplace)\n",
       "  (23): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (24): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (25): ReLU(inplace)\n",
       "  (26): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (27): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (28): ReLU(inplace)\n",
       "  (29): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "  (30): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (31): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (32): ReLU(inplace)\n",
       "  (33): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (34): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (35): ReLU(inplace)\n",
       "  (36): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (37): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (38): ReLU(inplace)\n",
       "  (39): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (40): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (41): ReLU(inplace)\n",
       "  (42): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (43): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (44): ReLU(inplace)\n",
       "  (45): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (46): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (47): ReLU(inplace)\n",
       "  (48): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (49): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (50): ReLU(inplace)\n",
       "  (51): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "  (52): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (53): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (54): ReLU(inplace)\n",
       "  (55): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (56): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (57): ReLU(inplace)\n",
       "  (58): Conv2d(128, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (59): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (60): ReLU(inplace)\n",
       "  (61): Conv2d(320, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (62): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (63): ReLU(inplace)\n",
       "  (64): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (65): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (66): ReLU(inplace)\n",
       "  (67): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (68): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (69): ReLU(inplace)\n",
       "  (70): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=0, dilation=(1, 1), ceil_mode=True)\n",
       "  (71): Conv2d(576, 224, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (72): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (73): ReLU(inplace)\n",
       "  (74): Conv2d(576, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (75): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (76): ReLU(inplace)\n",
       "  (77): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (78): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (79): ReLU(inplace)\n",
       "  (80): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (81): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (82): ReLU(inplace)\n",
       "  (83): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (84): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (85): ReLU(inplace)\n",
       "  (86): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (87): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (88): ReLU(inplace)\n",
       "  (89): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "  (90): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (91): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (92): ReLU(inplace)\n",
       "  (93): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (94): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (95): ReLU(inplace)\n",
       "  (96): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (97): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (98): ReLU(inplace)\n",
       "  (99): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (100): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (101): ReLU(inplace)\n",
       "  (102): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (103): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (104): ReLU(inplace)\n",
       "  (105): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (106): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (107): ReLU(inplace)\n",
       "  (108): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (109): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (110): ReLU(inplace)\n",
       "  (111): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "  (112): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (113): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (114): ReLU(inplace)\n",
       "  (115): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (116): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (117): ReLU(inplace)\n",
       "  (118): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (119): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (120): ReLU(inplace)\n",
       "  (121): Conv2d(128, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (122): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (123): ReLU(inplace)\n",
       "  (124): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (125): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (126): ReLU(inplace)\n",
       "  (127): Conv2d(128, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (128): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (129): ReLU(inplace)\n",
       "  (130): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (131): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (132): ReLU(inplace)\n",
       "  (133): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "  (134): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (135): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (136): ReLU(inplace)\n",
       "  (137): Conv2d(608, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (138): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (139): ReLU(inplace)\n",
       "  (140): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (141): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (142): ReLU(inplace)\n",
       "  (143): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (144): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (145): ReLU(inplace)\n",
       "  (146): Conv2d(608, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (147): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (148): ReLU(inplace)\n",
       "  (149): Conv2d(160, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (150): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (151): ReLU(inplace)\n",
       "  (152): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (153): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (154): ReLU(inplace)\n",
       "  (155): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "  (156): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (157): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (158): ReLU(inplace)\n",
       "  (159): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (160): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (161): ReLU(inplace)\n",
       "  (162): Conv2d(128, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (163): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (164): ReLU(inplace)\n",
       "  (165): Conv2d(608, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (166): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (167): ReLU(inplace)\n",
       "  (168): Conv2d(192, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (169): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (170): ReLU(inplace)\n",
       "  (171): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (172): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (173): ReLU(inplace)\n",
       "  (174): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=0, dilation=(1, 1), ceil_mode=True)\n",
       "  (175): Conv2d(1056, 352, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (176): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (177): ReLU(inplace)\n",
       "  (178): Conv2d(1056, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (179): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (180): ReLU(inplace)\n",
       "  (181): Conv2d(192, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (182): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (183): ReLU(inplace)\n",
       "  (184): Conv2d(1056, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (185): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (186): ReLU(inplace)\n",
       "  (187): Conv2d(160, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (188): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (189): ReLU(inplace)\n",
       "  (190): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (191): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (192): ReLU(inplace)\n",
       "  (193): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "  (194): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (195): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (196): ReLU(inplace)\n",
       "  (197): Conv2d(1024, 352, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (198): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (199): ReLU(inplace)\n",
       "  (200): Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (201): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (202): ReLU(inplace)\n",
       "  (203): Conv2d(192, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (204): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (205): ReLU(inplace)\n",
       "  (206): Conv2d(1024, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (207): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (208): ReLU(inplace)\n",
       "  (209): Conv2d(192, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (210): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (211): ReLU(inplace)\n",
       "  (212): Conv2d(224, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (213): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (214): ReLU(inplace)\n",
       "  (215): MaxPool2d(kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1), ceil_mode=True)\n",
       "  (216): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (217): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (218): ReLU(inplace)\n",
       "  (219): AdaptiveAvgPool2d(output_size=1)\n",
       "  (220): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (221): Dropout(p=0.5)\n",
       "  (222): Linear(in_features=1024, out_features=28, bias=True)\n",
       ")])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_ = learn.load(\"early_stopped_bn_inception\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='18' class='' max='50', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      36.00% [18/50 11:03:30<19:39:34]\n",
       "    </div>\n",
       "    \n",
       "<table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>fbeta</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.078928</th>\n",
       "    <th>0.079153</th>\n",
       "    <th>0.735258</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.077639</th>\n",
       "    <th>0.077838</th>\n",
       "    <th>0.738746</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>0.075514</th>\n",
       "    <th>0.077773</th>\n",
       "    <th>0.739398</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>0.077334</th>\n",
       "    <th>0.077646</th>\n",
       "    <th>0.740755</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>5</th>\n",
       "    <th>0.074387</th>\n",
       "    <th>0.076501</th>\n",
       "    <th>0.741506</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>6</th>\n",
       "    <th>0.074073</th>\n",
       "    <th>0.076511</th>\n",
       "    <th>0.741374</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>7</th>\n",
       "    <th>0.072825</th>\n",
       "    <th>0.076691</th>\n",
       "    <th>0.742515</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>8</th>\n",
       "    <th>0.071773</th>\n",
       "    <th>0.076487</th>\n",
       "    <th>0.747809</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>9</th>\n",
       "    <th>0.071588</th>\n",
       "    <th>0.076177</th>\n",
       "    <th>0.746872</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>10</th>\n",
       "    <th>0.072060</th>\n",
       "    <th>0.076120</th>\n",
       "    <th>0.748996</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>11</th>\n",
       "    <th>0.072596</th>\n",
       "    <th>0.075807</th>\n",
       "    <th>0.746894</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>12</th>\n",
       "    <th>0.072150</th>\n",
       "    <th>0.075263</th>\n",
       "    <th>0.746862</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>13</th>\n",
       "    <th>0.071429</th>\n",
       "    <th>0.075413</th>\n",
       "    <th>0.750883</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>14</th>\n",
       "    <th>0.070690</th>\n",
       "    <th>0.075459</th>\n",
       "    <th>0.749132</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>15</th>\n",
       "    <th>0.071198</th>\n",
       "    <th>0.075216</th>\n",
       "    <th>0.750039</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>16</th>\n",
       "    <th>0.070932</th>\n",
       "    <th>0.074986</th>\n",
       "    <th>0.747315</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>17</th>\n",
       "    <th>0.068453</th>\n",
       "    <th>0.075157</th>\n",
       "    <th>0.750241</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>18</th>\n",
       "    <th>0.069174</th>\n",
       "    <th>0.074574</th>\n",
       "    <th>0.751767</th>\n",
       "  </tr>\n",
       "</table>\n",
       "\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='98' class='' max='98', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [98/98 05:04<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: early stopping\n"
     ]
    }
   ],
   "source": [
    "learn.fit(50, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save(\"early_stopped_bn_inception_grad_acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='7' class='' max='8', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      87.50% [7/8 1:39:15<14:10]\n",
       "    </div>\n",
       "    \n",
       "\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='82' class='' max='183', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      44.81% [82/183 08:14<10:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds, avg_pred, y = learn.TTA(beta=None, scale=1.05, ds_type=DatasetType.Test)\n",
    "\n",
    "pred_labels = [' '.join(list([str(i) for i in np.nonzero(row > 0.2)[0]])) for row in np.array(avg_pred)]\n",
    "df = pd.DataFrame({'Id':test_ids,'Predicted':pred_labels})\n",
    "df.to_csv(path/'bn_inception_gradacc-avg_pred-0.2.csv', header=True, index=False)\n",
    "\n",
    "pred_labels = [' '.join(list([str(i) for i in np.nonzero(row > 0.2)[0]])) for row in np.array(preds)]\n",
    "df = pd.DataFrame({'Id':test_ids,'Predicted':pred_labels})\n",
    "df.to_csv(path/'bn_inception_gradacc-preds_v1-0.2.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pred_labels = [' '.join(list([str(i) for i in np.nonzero(row > 0.15)[0]])) for row in np.array(avg_pred)]\n",
    "df = pd.DataFrame({'Id':test_ids,'Predicted':pred_labels})\n",
    "df.to_csv(path/'bn_inception_gradacc-avg_pred-0.1.csv', header=True, index=False)\n",
    "\n",
    "pred_labels = [' '.join(list([str(i) for i in np.nonzero(row > 0.15)[0]])) for row in np.array(preds)]\n",
    "df = pd.DataFrame({'Id':test_ids,'Predicted':pred_labels})\n",
    "df.to_csv(path/'bn_inception_gradacc-preds_v1--0.1.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Try 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = F.binary_cross_entropy_with_logits\n",
    "model = get_net()\n",
    "model = model.cuda()\n",
    "optim = torch.optim.SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss_func(model:nn.Module, xb:Tensor, yb:Tensor, loss_func:OptLossFunc=None, opt:OptOptimizer=None,\n",
    "               cb_handler:Optional[CallbackHandler]=None)->Tuple[Union[Tensor,int,float,str]]:\n",
    "    if not is_listy(xb): xb = [xb]\n",
    "    if not is_listy(yb): yb = [yb]\n",
    "    out = model(*xb)\n",
    "    out = cb_handler.on_loss_begin(out)\n",
    "\n",
    "    if not loss_func: return to_detach(out), yb[0].detach()\n",
    "    loss = loss_func(out, *yb)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_fit(epochs:int, model:nn.Module, loss_func:LossFunction, opt:torch.optim.Optimizer,\n",
    "        data:DataBunch, callbacks:Optional[CallbackList]=None, metrics:OptMetrics=None,\n",
    "        gradient_accumulation_steps:int=32)->None:\n",
    "    \"Fit the `model` on `data` and learn using `loss_func` and `opt`.\"\n",
    "    cb_handler = CallbackHandler(callbacks, metrics)\n",
    "    pbar = master_bar(range(epochs))\n",
    "    cb_handler.on_train_begin(epochs, pbar=pbar, metrics=metrics)\n",
    "\n",
    "    exception=False\n",
    "    try:\n",
    "        for epoch in pbar:\n",
    "            step = 0\n",
    "            model.train()\n",
    "            cb_handler.on_epoch_begin()\n",
    "\n",
    "            for xb,yb in progress_bar(data.train_dl, parent=pbar):\n",
    "                xb, yb = cb_handler.on_batch_begin(xb, yb)\n",
    "                \n",
    "                loss = custom_loss_func(model, xb, yb, loss_func, cb_handler=cb_handler)\n",
    "                \n",
    "#                 if gradient_accumulation_steps > 1:\n",
    "#                     loss = loss / gradient_accumulation_steps\n",
    "                \n",
    "                loss = cb_handler.on_backward_begin(loss)\n",
    "                loss.backward()\n",
    "                cb_handler.on_backward_end()\n",
    "\n",
    "                if (step + 1) % gradient_accumulation_steps == 0:\n",
    "#                     print(\"Step:\", step, flush=True)\n",
    "                    opt.step()\n",
    "                    cb_handler.on_step_end()\n",
    "                    opt.zero_grad()\n",
    "                step += 1\n",
    "                \n",
    "                loss = loss.detach().cpu()  \n",
    "                if cb_handler.on_batch_end(loss): break\n",
    "\n",
    "            if not data.empty_val:\n",
    "                val_loss = validate(model, data.valid_dl, loss_func=loss_func, cb_handler=cb_handler, \n",
    "                                    pbar=pbar)\n",
    "            else: val_loss=None\n",
    "            if cb_handler.on_epoch_end(val_loss): break\n",
    "    except Exception as e:\n",
    "        exception = e\n",
    "        raise e\n",
    "    finally: cb_handler.on_train_end(exception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "defaults.lr = slice(3e-3)\n",
    "defaults.wd = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class custom_learner(basic_train.Learner):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "    def fit(self, epochs:int, lr:Union[Floats,slice]=defaults.lr, wd:Floats=None, \n",
    "            callbacks:Collection[Callback]=None) -> None:\n",
    "        lr = self.lr_range(lr)\n",
    "        if wd is None: wd = self.wd\n",
    "        if not getattr(self, 'opt', False): self.create_opt(lr, wd)\n",
    "        else: self.opt.lr,self.opt.wd = lr,wd\n",
    "        callbacks = [cb(self) for cb in self.callback_fns] + listify(callbacks)\n",
    "        custom_fit(epochs, self.model, self.loss_func, opt=self.opt, data=self.data, metrics=self.metrics,\n",
    "            callbacks=self.callbacks+callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = custom_learner(data, model, opt_func=optim, loss_func=loss_fn, metrics=[f1_score],\n",
    "                           callback_fns=[partial(ReduceLROnPlateauCallback, monitor='val_loss', \n",
    "                                                 patience=3),\n",
    "                                         partial(EarlyStoppingCallback, monitor='val_loss', \n",
    "                                                 min_delta=0.001, patience=9)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = learn.load(\"early_stopped_bn_inception_grad_acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = m.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(d, open('weights_grad_acc.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pickle.load(open('weights_grad_acc.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model.load_state_dict(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='10' class='' max='50', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      20.00% [10/50 5:36:37<22:26:31]\n",
       "    </div>\n",
       "    \n",
       "<table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>fbeta</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.065653</th>\n",
       "    <th>0.074131</th>\n",
       "    <th>0.751662</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.067026</th>\n",
       "    <th>0.074269</th>\n",
       "    <th>0.755607</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>0.065778</th>\n",
       "    <th>0.074161</th>\n",
       "    <th>0.751336</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>0.067045</th>\n",
       "    <th>0.074470</th>\n",
       "    <th>0.752458</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>5</th>\n",
       "    <th>0.066735</th>\n",
       "    <th>0.074253</th>\n",
       "    <th>0.752320</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>6</th>\n",
       "    <th>0.066035</th>\n",
       "    <th>0.074062</th>\n",
       "    <th>0.754735</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>7</th>\n",
       "    <th>0.067116</th>\n",
       "    <th>0.074138</th>\n",
       "    <th>0.754351</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>8</th>\n",
       "    <th>0.067207</th>\n",
       "    <th>0.074462</th>\n",
       "    <th>0.753540</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>9</th>\n",
       "    <th>0.067509</th>\n",
       "    <th>0.074326</th>\n",
       "    <th>0.756540</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>10</th>\n",
       "    <th>0.066314</th>\n",
       "    <th>0.074107</th>\n",
       "    <th>0.754046</th>\n",
       "  </tr>\n",
       "</table>\n",
       "\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='74' class='' max='98', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      75.51% [74/98 03:29<01:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: reducing lr to 0.0002\n",
      "Epoch 10: reducing lr to 4e-05\n"
     ]
    }
   ],
   "source": [
    "learn.fit(50, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(\"early_stopped_bn_inception_grad_acc_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
